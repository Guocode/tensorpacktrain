[32m[1212 23:00:47 @logger.py:85][0m Argv: C:/Users/Guo/PycharmProjects/untitled4/train.py --load train_log/cifar10-preact18/checkpoint
[32m[1212 23:00:48 @input_source.py:219][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[1212 23:00:48 @trainers.py:52][0m Building graph for a single training tower ...
[32m[1212 23:00:50 @registry.py:121][0m conv0 input: [None, 3, 96, 96]
[32m[1212 23:00:50 @registry.py:129][0m conv0 output: [None, 64, 96, 96]
[32m[1212 23:00:50 @registry.py:121][0m res0.0/conv1 input: [None, 64, 96, 96]
[32m[1212 23:00:50 @registry.py:129][0m res0.0/conv1 output: [None, 32, 96, 96]
[32m[1212 23:00:50 @registry.py:121][0m res0.0/conv2 input: [None, 32, 96, 96]
[32m[1212 23:00:50 @registry.py:129][0m res0.0/conv2 output: [None, 32, 96, 96]
[32m[1212 23:00:50 @registry.py:121][0m res0.0/shortcut input: [None, 64, 96, 96]
[32m[1212 23:00:50 @registry.py:129][0m res0.0/shortcut output: [None, 32, 96, 96]
[32m[1212 23:00:51 @registry.py:121][0m res0.1/conv1 input: [None, 32, 96, 96]
[32m[1212 23:00:51 @registry.py:129][0m res0.1/conv1 output: [None, 32, 96, 96]
[32m[1212 23:00:51 @registry.py:121][0m res0.1/conv2 input: [None, 32, 96, 96]
[32m[1212 23:00:51 @registry.py:129][0m res0.1/conv2 output: [None, 32, 96, 96]
[32m[1212 23:00:51 @registry.py:121][0m res1.0/conv1 input: [None, 32, 96, 96]
[32m[1212 23:00:51 @registry.py:129][0m res1.0/conv1 output: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:121][0m res1.0/conv2 input: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:129][0m res1.0/conv2 output: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:121][0m res1.0/shortcut input: [None, 32, 96, 96]
[32m[1212 23:00:51 @registry.py:129][0m res1.0/shortcut output: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:121][0m res1.1/conv1 input: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:129][0m res1.1/conv1 output: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:121][0m res1.1/conv2 input: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:129][0m res1.1/conv2 output: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:121][0m res2.0/conv1 input: [None, 64, 48, 48]
[32m[1212 23:00:51 @registry.py:129][0m res2.0/conv1 output: [None, 128, 24, 24]
[32m[1212 23:00:51 @registry.py:121][0m res2.0/conv2 input: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:129][0m res2.0/conv2 output: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:121][0m res2.0/shortcut input: [None, 64, 48, 48]
[32m[1212 23:00:52 @registry.py:129][0m res2.0/shortcut output: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:121][0m res2.1/conv1 input: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:129][0m res2.1/conv1 output: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:121][0m res2.1/conv2 input: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:129][0m res2.1/conv2 output: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:121][0m res3.0/conv1 input: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:129][0m res3.0/conv1 output: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:121][0m res3.0/conv2 input: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:129][0m res3.0/conv2 output: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:121][0m res3.0/shortcut input: [None, 128, 24, 24]
[32m[1212 23:00:52 @registry.py:129][0m res3.0/shortcut output: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:121][0m res3.1/conv1 input: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:129][0m res3.1/conv1 output: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:121][0m res3.1/conv2 input: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:129][0m res3.1/conv2 output: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:121][0m gap input: [None, 256, 12, 12]
[32m[1212 23:00:52 @registry.py:129][0m gap output: [None, 256]
[32m[1212 23:00:52 @registry.py:121][0m linear input: [None, 256]
[32m[1212 23:00:52 @registry.py:129][0m linear output: [None, 10]
[32m[1212 23:00:53 @regularize.py:90][0m regularize_cost() found 55 variables to regularize.
[32m[1212 23:00:53 @regularize.py:19][0m The following tensors will be regularized: conv0/W:0, res0.0/bn/gamma:0, res0.0/bn/beta:0, res0.0/conv1/W:0, res0.0/conv1/bn/gamma:0, res0.0/conv1/bn/beta:0, res0.0/conv2/W:0, res0.0/shortcut/W:0, res0.1/bn/gamma:0, res0.1/bn/beta:0, res0.1/conv1/W:0, res0.1/conv1/bn/gamma:0, res0.1/conv1/bn/beta:0, res0.1/conv2/W:0, res1.0/bn/gamma:0, res1.0/bn/beta:0, res1.0/conv1/W:0, res1.0/conv1/bn/gamma:0, res1.0/conv1/bn/beta:0, res1.0/conv2/W:0, res1.0/shortcut/W:0, res1.1/bn/gamma:0, res1.1/bn/beta:0, res1.1/conv1/W:0, res1.1/conv1/bn/gamma:0, res1.1/conv1/bn/beta:0, res1.1/conv2/W:0, res2.0/bn/gamma:0, res2.0/bn/beta:0, res2.0/conv1/W:0, res2.0/conv1/bn/gamma:0, res2.0/conv1/bn/beta:0, res2.0/conv2/W:0, res2.0/shortcut/W:0, res2.1/bn/gamma:0, res2.1/bn/beta:0, res2.1/conv1/W:0, res2.1/conv1/bn/gamma:0, res2.1/conv1/bn/beta:0, res2.1/conv2/W:0, res3.0/bn/gamma:0, res3.0/bn/beta:0, res3.0/conv1/W:0, res3.0/conv1/bn/gamma:0, res3.0/conv1/bn/beta:0, res3.0/conv2/W:0, res3.0/shortcut/W:0, res3.1/bn/gamma:0, res3.1/bn/beta:0, res3.1/conv1/W:0, res3.1/conv1/bn/gamma:0, res3.1/conv1/bn/beta:0, res3.1/conv2/W:0, linear/W:0, linear/b:0
[32m[1212 23:00:54 @model_utils.py:64][0m [36mTrainable Variables: 
[0mname                     shape                dim
-----------------------  ----------------  ------
conv0/W:0                [3, 3, 3, 64]       1728
res0.0/bn/gamma:0        [64]                  64
res0.0/bn/beta:0         [64]                  64
res0.0/conv1/W:0         [3, 3, 64, 32]     18432
res0.0/conv1/bn/gamma:0  [32]                  32
res0.0/conv1/bn/beta:0   [32]                  32
res0.0/conv2/W:0         [3, 3, 32, 32]      9216
res0.0/shortcut/W:0      [1, 1, 64, 32]      2048
res0.1/bn/gamma:0        [32]                  32
res0.1/bn/beta:0         [32]                  32
res0.1/conv1/W:0         [3, 3, 32, 32]      9216
res0.1/conv1/bn/gamma:0  [32]                  32
res0.1/conv1/bn/beta:0   [32]                  32
res0.1/conv2/W:0         [3, 3, 32, 32]      9216
res1.0/bn/gamma:0        [32]                  32
res1.0/bn/beta:0         [32]                  32
res1.0/conv1/W:0         [3, 3, 32, 64]     18432
res1.0/conv1/bn/gamma:0  [64]                  64
res1.0/conv1/bn/beta:0   [64]                  64
res1.0/conv2/W:0         [3, 3, 64, 64]     36864
res1.0/shortcut/W:0      [1, 1, 32, 64]      2048
res1.1/bn/gamma:0        [64]                  64
res1.1/bn/beta:0         [64]                  64
res1.1/conv1/W:0         [3, 3, 64, 64]     36864
res1.1/conv1/bn/gamma:0  [64]                  64
res1.1/conv1/bn/beta:0   [64]                  64
res1.1/conv2/W:0         [3, 3, 64, 64]     36864
res2.0/bn/gamma:0        [64]                  64
res2.0/bn/beta:0         [64]                  64
res2.0/conv1/W:0         [3, 3, 64, 128]    73728
res2.0/conv1/bn/gamma:0  [128]                128
res2.0/conv1/bn/beta:0   [128]                128
res2.0/conv2/W:0         [3, 3, 128, 128]  147456
res2.0/shortcut/W:0      [1, 1, 64, 128]     8192
res2.1/bn/gamma:0        [128]                128
res2.1/bn/beta:0         [128]                128
res2.1/conv1/W:0         [3, 3, 128, 128]  147456
res2.1/conv1/bn/gamma:0  [128]                128
res2.1/conv1/bn/beta:0   [128]                128
res2.1/conv2/W:0         [3, 3, 128, 128]  147456
res3.0/bn/gamma:0        [128]                128
res3.0/bn/beta:0         [128]                128
res3.0/conv1/W:0         [3, 3, 128, 256]  294912
res3.0/conv1/bn/gamma:0  [256]                256
res3.0/conv1/bn/beta:0   [256]                256
res3.0/conv2/W:0         [3, 3, 256, 256]  589824
res3.0/shortcut/W:0      [1, 1, 128, 256]   32768
res3.1/bn/gamma:0        [256]                256
res3.1/bn/beta:0         [256]                256
res3.1/conv1/W:0         [3, 3, 256, 256]  589824
res3.1/conv1/bn/gamma:0  [256]                256
res3.1/conv1/bn/beta:0   [256]                256
res3.1/conv2/W:0         [3, 3, 256, 256]  589824
linear/W:0               [256, 10]           2560
linear/b:0               [10]                  10[36m
Total #vars=55, #params=2808394, size=10.71MB[0m
[32m[1212 23:00:54 @base.py:209][0m Setup callbacks graph ...
[32m[1212 23:00:54 @inference_runner.py:154][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[1212 23:00:54 @summary.py:38][0m Maintain moving average summary of 2 tensors in collection MOVING_SUMMARY_OPS.
[32m[1212 23:00:54 @summary.py:75][0m Summarizing collection 'summaries' of size 25.
[32m[1212 23:00:54 @graph.py:91][0m Applying collection UPDATE_OPS of 32 ops.
[32m[1212 23:00:55 @base.py:230][0m Creating the session ...
[32m[1212 23:00:56 @base.py:236][0m Initializing the session ...
[32m[1212 23:00:56 @sessinit.py:115][0m Restoring checkpoint from train_log/cifar10-preact18\model-16146 ...
[32m[1212 23:00:56 @base.py:243][0m Graph Finalized.
[32m[1212 23:00:56 @concurrency.py:37][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[1212 23:00:56 @steps.py:126][0m Start training with global_step=16146
[32m[1212 23:00:56 @inference_runner.py:101][0m [InferenceRunner] Will eval 225 iterations
[32m[1212 23:00:56 @param.py:158][0m [HyperParamSetter] At global_step=16146, learning_rate is set to 0.010000
[32m[1212 23:00:56 @base.py:275][0m Start Epoch 1 ...
[32m[1212 23:06:11 @base.py:285][0m Epoch 1 (global_step 17043) finished, time:5 minutes 14 seconds.
[32m[1212 23:06:11 @saver.py:77][0m Model saved to train_log/fer-preact18\model-17043.
[32m[1212 23:06:36 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:06:36 @monitor.py:459][0m cross_entropy_loss: 1.1195
[32m[1212 23:06:36 @monitor.py:459][0m train_error: 0.43068
[32m[1212 23:06:36 @monitor.py:459][0m validation_cost: 1.1247
[32m[1212 23:06:36 @monitor.py:459][0m validation_error: 0.42867
[32m[1212 23:06:36 @group.py:48][0m Callbacks took 25.792 sec in total. InferenceRunner: 25.4 seconds
[32m[1212 23:06:36 @base.py:275][0m Start Epoch 2 ...
[32m[1212 23:11:45 @base.py:285][0m Epoch 2 (global_step 17940) finished, time:5 minutes 9 seconds.
[32m[1212 23:11:46 @saver.py:77][0m Model saved to train_log/fer-preact18\model-17940.
[32m[1212 23:12:10 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:12:10 @monitor.py:459][0m cross_entropy_loss: 1.093
[32m[1212 23:12:10 @monitor.py:459][0m train_error: 0.41474
[32m[1212 23:12:10 @monitor.py:459][0m validation_cost: 1.1087
[32m[1212 23:12:10 @monitor.py:459][0m validation_error: 0.42143
[32m[1212 23:12:10 @group.py:48][0m Callbacks took 24.949 sec in total. InferenceRunner: 24.6 seconds
[32m[1212 23:12:10 @base.py:275][0m Start Epoch 3 ...
[32m[1212 23:17:19 @base.py:285][0m Epoch 3 (global_step 18837) finished, time:5 minutes 8 seconds.
[32m[1212 23:17:20 @saver.py:77][0m Model saved to train_log/fer-preact18\model-18837.
[32m[1212 23:17:45 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:17:45 @monitor.py:459][0m cross_entropy_loss: 1.057
[32m[1212 23:17:45 @monitor.py:459][0m train_error: 0.41185
[32m[1212 23:17:45 @monitor.py:459][0m validation_cost: 1.1009
[32m[1212 23:17:45 @monitor.py:459][0m validation_error: 0.41516
[32m[1212 23:17:45 @group.py:48][0m Callbacks took 25.470 sec in total. InferenceRunner: 25.1 seconds
[32m[1212 23:17:45 @base.py:275][0m Start Epoch 4 ...
[32m[1212 23:22:51 @base.py:285][0m Epoch 4 (global_step 19734) finished, time:5 minutes 6 seconds.
[32m[1212 23:22:51 @saver.py:77][0m Model saved to train_log/fer-preact18\model-19734.
[32m[1212 23:23:17 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:23:17 @monitor.py:459][0m cross_entropy_loss: 1.0767
[32m[1212 23:23:17 @monitor.py:459][0m train_error: 0.39761
[32m[1212 23:23:17 @monitor.py:459][0m validation_cost: 1.1058
[32m[1212 23:23:17 @monitor.py:459][0m validation_error: 0.41864
[32m[1212 23:23:17 @group.py:48][0m Callbacks took 25.616 sec in total. InferenceRunner: 25.2 seconds
[32m[1212 23:23:17 @base.py:275][0m Start Epoch 5 ...
[32m[1212 23:28:23 @base.py:285][0m Epoch 5 (global_step 20631) finished, time:5 minutes 6 seconds.
[32m[1212 23:28:24 @saver.py:77][0m Model saved to train_log/fer-preact18\model-20631.
[32m[1212 23:28:50 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:28:50 @monitor.py:459][0m cross_entropy_loss: 1.055
[32m[1212 23:28:50 @monitor.py:459][0m train_error: 0.38777
[32m[1212 23:28:50 @monitor.py:459][0m validation_cost: 1.0986
[32m[1212 23:28:50 @monitor.py:459][0m validation_error: 0.41335
[32m[1212 23:28:50 @group.py:48][0m Callbacks took 26.504 sec in total. InferenceRunner: 26.1 seconds
[32m[1212 23:28:50 @base.py:275][0m Start Epoch 6 ...
[32m[1212 23:33:56 @base.py:285][0m Epoch 6 (global_step 21528) finished, time:5 minutes 6 seconds.
[32m[1212 23:33:56 @saver.py:77][0m Model saved to train_log/fer-preact18\model-21528.
[32m[1212 23:34:21 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:34:21 @monitor.py:459][0m cross_entropy_loss: 1.0304
[32m[1212 23:34:21 @monitor.py:459][0m train_error: 0.37656
[32m[1212 23:34:21 @monitor.py:459][0m validation_cost: 1.0829
[32m[1212 23:34:21 @monitor.py:459][0m validation_error: 0.41
[32m[1212 23:34:21 @group.py:48][0m Callbacks took 25.100 sec in total. InferenceRunner: 24.7 seconds
[32m[1212 23:34:21 @base.py:275][0m Start Epoch 7 ...
[32m[1212 23:39:27 @base.py:285][0m Epoch 7 (global_step 22425) finished, time:5 minutes 5 seconds.
[32m[1212 23:39:27 @saver.py:77][0m Model saved to train_log/fer-preact18\model-22425.
[32m[1212 23:39:53 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:39:53 @monitor.py:459][0m cross_entropy_loss: 1.0256
[32m[1212 23:39:53 @monitor.py:459][0m train_error: 0.40011
[32m[1212 23:39:53 @monitor.py:459][0m validation_cost: 1.0817
[32m[1212 23:39:53 @monitor.py:459][0m validation_error: 0.41028
[32m[1212 23:39:53 @group.py:48][0m Callbacks took 26.126 sec in total. InferenceRunner: 25.7 seconds
[32m[1212 23:39:53 @base.py:275][0m Start Epoch 8 ...
[32m[1212 23:45:00 @base.py:285][0m Epoch 8 (global_step 23322) finished, time:5 minutes 6 seconds.
[32m[1212 23:45:00 @saver.py:77][0m Model saved to train_log/fer-preact18\model-23322.
[32m[1212 23:45:26 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:45:26 @monitor.py:459][0m cross_entropy_loss: 0.99051
[32m[1212 23:45:26 @monitor.py:459][0m train_error: 0.36762
[32m[1212 23:45:26 @monitor.py:459][0m validation_cost: 1.0712
[32m[1212 23:45:26 @monitor.py:459][0m validation_error: 0.39969
[32m[1212 23:45:26 @group.py:48][0m Callbacks took 26.095 sec in total. InferenceRunner: 25.7 seconds
[32m[1212 23:45:26 @base.py:275][0m Start Epoch 9 ...
[32m[1212 23:50:33 @base.py:285][0m Epoch 9 (global_step 24219) finished, time:5 minutes 6 seconds.
[32m[1212 23:50:33 @saver.py:77][0m Model saved to train_log/fer-preact18\model-24219.
[32m[1212 23:50:57 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:50:57 @monitor.py:459][0m cross_entropy_loss: 0.99562
[32m[1212 23:50:57 @monitor.py:459][0m train_error: 0.36586
[32m[1212 23:50:57 @monitor.py:459][0m validation_cost: 1.0747
[32m[1212 23:50:57 @monitor.py:459][0m validation_error: 0.40736
[32m[1212 23:50:57 @group.py:48][0m Callbacks took 24.050 sec in total. InferenceRunner: 23.6 seconds
[32m[1212 23:50:57 @base.py:275][0m Start Epoch 10 ...
[32m[1212 23:56:04 @base.py:285][0m Epoch 10 (global_step 25116) finished, time:5 minutes 6 seconds.
[32m[1212 23:56:04 @saver.py:77][0m Model saved to train_log/fer-preact18\model-25116.
[32m[1212 23:56:28 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1212 23:56:28 @monitor.py:459][0m cross_entropy_loss: 0.99393
[32m[1212 23:56:28 @monitor.py:459][0m train_error: 0.3822
[32m[1212 23:56:28 @monitor.py:459][0m validation_cost: 1.0722
[32m[1212 23:56:28 @monitor.py:459][0m validation_error: 0.40192
[32m[1212 23:56:28 @group.py:48][0m Callbacks took 24.351 sec in total. InferenceRunner: 24 seconds
[32m[1212 23:56:28 @base.py:275][0m Start Epoch 11 ...
[32m[1213 00:01:35 @base.py:285][0m Epoch 11 (global_step 26013) finished, time:5 minutes 7 seconds.
[32m[1213 00:01:36 @saver.py:77][0m Model saved to train_log/fer-preact18\model-26013.
[32m[1213 00:02:00 @monitor.py:459][0m QueueInput/queue_size: 50
[32m[1213 00:02:00 @monitor.py:459][0m cross_entropy_loss: 0.99638
[32m[1213 00:02:00 @monitor.py:459][0m train_error: 0.36745
[32m[1213 00:02:00 @monitor.py:459][0m validation_cost: 1.0751
[32m[1213 00:02:00 @monitor.py:459][0m validation_error: 0.40164
[32m[1213 00:02:00 @group.py:48][0m Callbacks took 24.397 sec in total. InferenceRunner: 24 seconds
[32m[1213 00:02:00 @base.py:275][0m Start Epoch 12 ...
